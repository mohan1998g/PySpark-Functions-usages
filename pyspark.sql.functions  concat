pyspark.sql.functions.concat

Concatenates multiple input columns together into a single column. 
The function works with strings, numeric, binary and compatible array columns.

Parameters
cols : Column or str
            target column or columns to work on.

Returns : Column
            concatenated values. Type of the Column depends on input columnsâ€™ type.

Examples

df = spark.createDataFrame([('abcd','123')], ['s', 'd'])
df.show()
+----+---+
|   s|  d|
+----+---+
|abcd|123|
+----+---+

df = df.select(concat(df.s, df.d).alias('s'))
df.show()
+-------+
|      s|
+-------+
|abcd123|
+-------+

df = spark.createDataFrame([([1, 2], [3, 4], [5]), ([1, 2], None, [3])], ['a', 'b', 'c'])
df.show()
+------+------+---+
|     a|     b|  c|
+------+------+---+
|[1, 2]|[3, 4]|[5]|
|[1, 2]|  NULL|[3]|
+------+------+---+

df = df.select(concat(df.a, df.b, df.c).alias("arr"))
df.show()
+---------------+
|            arr|
+---------------+
|[1, 2, 3, 4, 5]|
|           NULL|
+---------------+


See also

pyspark.sql.functions.array_join()
to concatenate string columns with delimiter
